{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "431c2c14",
   "metadata": {},
   "source": [
    "## solution to 2.2.b) optional\n",
    "First we load the image with `PIL` and convert it to an array with `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image #Class from PIL module to handle images\n",
    "import numpy as np # standard python module for numerical calculation\n",
    "import matplotlib.pyplot as plt # standard python module for plotting\n",
    "import treecorr # module to use TreeCorr's code\n",
    "\n",
    "# define the correlation function - brute force\n",
    "\n",
    "def corrKK(cat,rmin,rmax,nrbin):\n",
    "        \n",
    "    # function to calculate distance r\n",
    "    def get_r(A=[],B=[]):\n",
    "        return np.linalg.norm(np.array(A)-np.array(B))\n",
    "    \n",
    "    # function to get the bin for the estimator. It returns linear binning if inputed linear values,\n",
    "    # logarithmic binning for inputed log values\n",
    "    def binning(x,xmin,xBinsize):\n",
    "        return int((x-xmin)/(xBinsize+10**(-5)))\n",
    "\n",
    "    # initialize vars\n",
    "    \n",
    "    # define bin size in logarithm space\n",
    "    rBinsize = np.log(rmax/rmin)/nrbin \n",
    "    \n",
    "    # define array to store the correlation function \n",
    "    xikk = np.zeros(nrbin)\n",
    "    \n",
    "    # define array to count number of points in each bin; corresponds to the denominator in the above equation\n",
    "    binCntr = xikk.copy()\n",
    "    \n",
    "    # calculate and store in xikk\n",
    "    for ii,p1 in enumerate(cat):# catalog 1\n",
    "        for jj,p2 in enumerate(cat):# catalog 2\n",
    "            \n",
    "            # avoid count twice over pairs\n",
    "            if jj >= ii: continue\n",
    "                \n",
    "            # get the distance between pairs\n",
    "            r=get_r(p1[:2],p2[:2])\n",
    "            \n",
    "            # check distance belongs to estimator range\n",
    "            if r < rmin or r >= rmax:continue\n",
    "            \n",
    "            # if distance is within the relevant range store the correlation of points into bins\n",
    "            xikk[binning(np.log(r),np.log(rmin),rBinsize)] += p1[-1]*p2[-1]\n",
    "            binCntr[binning(np.log(r),np.log(rmin),rBinsize)] += 1  \n",
    "            \n",
    "    # normalize xikk\n",
    "    for ii in range(nrbin):\n",
    "        if binCntr[ii] == 0 :continue\n",
    "        xikk[ii] = xikk[ii]/binCntr[ii]\n",
    "            \n",
    "    return [xikk,binCntr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"images/triforce.png\") # import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c84ab1",
   "metadata": {},
   "source": [
    "This image has as many pixels in x and y directions as its width and height "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ada001",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"heigh:{}, width:{}\".format(img.height,img.width))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635187b",
   "metadata": {},
   "source": [
    "So we can convert this image to an array having as many entries as width and height, but first let us change this image to gray scale with the method [convert](https://pillow.readthedocs.io/en/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b95a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cboat=np.asarray(img.convert(\"L\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad602a",
   "metadata": {},
   "source": [
    "the image now is an array for every row and col it has a color associated with the pixel. Let us watch this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cboat[15:18])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aeb3e0",
   "metadata": {},
   "source": [
    "We can visualize this array with `matplotlib.imshow`, to appreciate lets load a cmap in grey scale _gs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7291c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs=plt.cm.get_cmap('binary').reversed() # color map to binary \n",
    "vs=plt.cm.get_cmap('viridis').reversed() # color map to viridis\n",
    "fooimg=plt.imshow(cboat,cmap=gs,vmin=np.min(cboat),vmax=np.max(cboat))\n",
    "plt.colorbar(fooimg);plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d4355",
   "metadata": {},
   "source": [
    "Even though we see white pixels causing no problem, it is since they have a value asociated which result in _noise_ so we better reduce those values. For example normalizing and substracting the mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb=cboat/np.max(cboat)\n",
    "cb=cb-np.mean(cb)\n",
    "cb=cb-cb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f079490",
   "metadata": {},
   "source": [
    "now values of $c$ belong to [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbmin = np.min(cb);\n",
    "cbmax = np.max(cb);\n",
    "print(\"min(kb)=%5.2f,max(kb)=%5.2f\" %(cbmin,cbmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd4a57",
   "metadata": {},
   "source": [
    "We take a look to the \"enhanced\" image array which may look very similar to eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fooimg=plt.imshow(cb,cmap=gs,vmin=cbmin,vmax=cbmax)\n",
    "plt.colorbar(fooimg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd309774",
   "metadata": {},
   "source": [
    "On one hand we are gonna work with gray scale level, but on the other hand notice we now are working with pixels distance instead of physical distance. So we want to create _RA_ and _DEC_ arrays for this case in pixel distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50628eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raPix=np.arange(img.width);\n",
    "decPix=np.arange(img.height);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e965c",
   "metadata": {},
   "source": [
    "Furthermore, to handle every pixel from the image we need to give positions to them; maybe work with masks afterward. Then, we first create the _RA_ and _DEC_ with as many entries as our c-field has, i.e., the shape of _cb_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd450b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c747fc",
   "metadata": {},
   "source": [
    "therefore we need _RA_ and _DEC_ with 400 entries, since we have 400 pixels. We make a 1D array for c out of cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95288cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb1d=np.reshape(cb,(-1))\n",
    "print(cb1d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77df707",
   "metadata": {},
   "source": [
    "And for making those 400 entries with the same order, as a meshgrid flattened, we use `numpy.meshgrid` and then we flatten it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a87767",
   "metadata": {},
   "outputs": [],
   "source": [
    "RA,DEC=np.meshgrid(decPix,raPix)\n",
    "RA=np.reshape(RA,(-1))\n",
    "DEC=np.reshape(DEC,(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905b00d",
   "metadata": {},
   "source": [
    "We now have the ingredients for creat a catalog, as for TC or for brute force algorithm. Wheater one or another we define the minimal, maximal distances and number of bins for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53694a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum distance for correlation in image\n",
    "rminImg=1;\n",
    "\n",
    "# maximum distance for correlation in image\n",
    "rmaxImg=np.sqrt(2)*img.width;\n",
    "\n",
    "# number of bins in distance for the correlation of c-field\n",
    "nrbinImg=12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d3c359",
   "metadata": {},
   "source": [
    "Since `corrKK` recieves a catalog with [ra,dec,k], we create one and run `corrKK` for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "catImgbf=np.transpose(np.reshape([RA,DEC,cb1d],(3,len(cb1d))))\n",
    "xiImg,binCntrImg=corrKK(catImgbf,rminImg,rmaxImg,nrbinImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a1f458",
   "metadata": {},
   "source": [
    "For TC we do not need to create a catalog as above but by means of `treecorr.Catalog` class, then create a `treecorr.KKCorrelation` instance and finally run the calculation of $\\xi$ with `treecorr.KKCorrelation`. We recommend you to checkout [TC's documentation](https://rmjarvis.github.io/TreeCorr/_build/html/kk.html) for deeper insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a647781",
   "metadata": {},
   "outputs": [],
   "source": [
    "catImg=treecorr.Catalog(ra=RA,dec=DEC,k=cb1d,ra_units='deg', dec_units='deg')\n",
    "tcKKcorrImg=treecorr.KKCorrelation(sep_units=\"deg\",min_sep=rminImg,max_sep=rmaxImg,nbins=nrbinImg)\n",
    "tcKKcorrImg.process(catImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb4b00",
   "metadata": {},
   "source": [
    "Once done with calculation, let us see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tcKKcorrImg.rnom,tcKKcorrImg.xi,c=\"black\",label=\"$\\\\xi_{TC}$\")\n",
    "plt.plot(tcKKcorrImg.rnom,xiImg,linestyle=\"dashed\",marker=\".\",markersize=12,label=\"$\\\\xi_{BF}$\",c=\"black\")\n",
    "plt.legend(frameon=False,fontsize=15);plt.xlabel(\"$r$\")\n",
    "#plt.xlim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52036f",
   "metadata": {},
   "source": [
    "Notice the peaks are very similar, maybe only shifted wich can be a result araising from inner TC's methods for binning and smarter procedure for the calculation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
